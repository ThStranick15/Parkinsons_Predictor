{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl1_4HUc1O0A"
      },
      "outputs": [],
      "source": [
        "#CycleGAN Implementation\n",
        "#Running with Nvidia Cuda GPU each 200 epoch training takes ~45min\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#check if can use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "#randomizing input image transforms\n",
        "class SpiralDataset(Dataset):\n",
        "    def __init__(self, folder, img_size=(256, 256)):\n",
        "        self.paths = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.jpg')]\n",
        "        resize_size = random.randint(286, 300)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((resize_size, resize_size)),\n",
        "            transforms.RandomCrop(img_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        return self.transform(img)\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(dim, dim, kernel_size=3, padding=0),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)  # Skip connection\n",
        "\n",
        "#Generator block for generation of new images\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=6):\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "        model = []\n",
        "\n",
        "        # Initial conv\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),\n",
        "            nn.InstanceNorm2d(ngf),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = ngf\n",
        "        out_features = ngf * 2\n",
        "        for _ in range(2):  # Two downsamples\n",
        "            model += [\n",
        "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features * 2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features // 2\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features // 2\n",
        "\n",
        "        # Output layer\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
        "            nn.Tanh()\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "#discriminator block for determining domain of images\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 1, 4, 1, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "bce_loss = nn.BCEWithLogitsLoss()\n",
        "l1_loss = nn.L1Loss()\n",
        "\n",
        "#training step of CycleGAN model\n",
        "def train_step(real_A, real_B, G_AB, G_BA, D_A, D_B, opt_G, opt_D_A, opt_D_B, lambda_cycle=10, lambda_identity=0.5):\n",
        "    # Move data to device\n",
        "    real_A, real_B = real_A.to(device, non_blocking=True), real_B.to(device, non_blocking=True)\n",
        "\n",
        "    # === Generators ===\n",
        "    opt_G.zero_grad()\n",
        "\n",
        "    fake_B = G_AB(real_A)\n",
        "    fake_A = G_BA(real_B)\n",
        "    rec_A = G_BA(fake_B)\n",
        "    rec_B = G_AB(fake_A)\n",
        "\n",
        "    same_A = G_BA(real_A)\n",
        "    same_B = G_AB(real_B)\n",
        "\n",
        "    # Adversarial loss\n",
        "    loss_G_AB = bce_loss(D_B(fake_B), torch.ones_like(D_B(fake_B)))\n",
        "    loss_G_BA = bce_loss(D_A(fake_A), torch.ones_like(D_A(fake_A)))\n",
        "\n",
        "    # Cycle loss\n",
        "    loss_cycle_A = l1_loss(rec_A, real_A)\n",
        "    loss_cycle_B = l1_loss(rec_B, real_B)\n",
        "\n",
        "    # Identity loss\n",
        "    loss_identity_A = l1_loss(same_A, real_A)\n",
        "    loss_identity_B = l1_loss(same_B, real_B)\n",
        "\n",
        "    # Total generator loss\n",
        "    total_G = loss_G_AB + loss_G_BA + lambda_cycle * (loss_cycle_A + loss_cycle_B) + lambda_identity * (loss_identity_A + loss_identity_B)\n",
        "    total_G.backward()\n",
        "    opt_G.step()\n",
        "\n",
        "    # === Discriminator A ===\n",
        "    opt_D_A.zero_grad()\n",
        "    loss_D_A = bce_loss(D_A(real_A), torch.ones_like(D_A(real_A))) + bce_loss(D_A(fake_A.detach()), torch.zeros_like(D_A(fake_A)))\n",
        "    loss_D_A.backward()\n",
        "    opt_D_A.step()\n",
        "\n",
        "    # === Discriminator B ===\n",
        "    opt_D_B.zero_grad()\n",
        "    loss_D_B = bce_loss(D_B(real_B), torch.ones_like(D_B(real_B))) + bce_loss(D_B(fake_B.detach()), torch.zeros_like(D_B(fake_B)))\n",
        "    loss_D_B.backward()\n",
        "    opt_D_B.step()\n",
        "\n",
        "    return total_G.item(), loss_D_A.item(), loss_D_B.item()\n",
        "\n",
        "#training of CycleGAN\n",
        "def train(domain_A,domain_B):\n",
        "    dataset_A = DataLoader(SpiralDataset(domain_A), batch_size=1, shuffle=True, pin_memory=True)\n",
        "    dataset_B = DataLoader(SpiralDataset(domain_B), batch_size=1, shuffle=True, pin_memory=True)\n",
        "\n",
        "    G_AB = ResnetGenerator().to(device)\n",
        "    G_BA = ResnetGenerator().to(device)\n",
        "    D_A = Discriminator().to(device)\n",
        "    D_B = Discriminator().to(device)\n",
        "\n",
        "    opt_G = torch.optim.Adam(list(G_AB.parameters()) + list(G_BA.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "    opt_D_A = torch.optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    opt_D_B = torch.optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(200):\n",
        "\n",
        "        for real_A, real_B in zip(dataset_A, dataset_B):\n",
        "            g_loss, dA_loss, dB_loss = train_step(real_A, real_B, G_AB, G_BA, D_A, D_B, opt_G, opt_D_A, opt_D_B)\n",
        "        print(f\"Epoch {epoch} - Gen Loss: {g_loss:.4f} | Disc A: {dA_loss:.4f} | Disc B: {dB_loss:.4f}\")\n",
        "        if epoch % 10 == 0:\n",
        "            G_AB.eval()\n",
        "            with torch.no_grad():\n",
        "                sample_input = real_A.to(device)\n",
        "                fake_B = G_AB(sample_input)\n",
        "                # Denormalize real A (input)\n",
        "                real_A_img = sample_input.squeeze(0).cpu() * 0.5 + 0.5\n",
        "                real_A_img = real_A_img.permute(1, 2, 0).clamp(0, 1).numpy()\n",
        "                fake_B = fake_B.squeeze(0).cpu() * 0.5 + 0.5  # Denormalize\n",
        "                fake_B = fake_B.permute(1, 2, 0).clamp(0, 1).numpy()\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(real_A_img)\n",
        "            plt.title(f\"Epoch {epoch}: Real A (Input)\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(fake_B)\n",
        "            plt.title(f\"Epoch {epoch}: Fake B (Output)\")\n",
        "            plt.axis(\"off\")\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            G_AB.train()\n",
        "    return G_AB, G_BA\n",
        "\n",
        "#cleaned control 0305 deleted patient 0009 0153 0202 0219 0261\n",
        "#cleaned meander control 0305 deleted patient 0023 0024 0153 0202\n",
        "\n",
        "G_Spiral_Control_Patient, G_Spiral_Control_Patient_Back = train(\"FDM Resources/SpiralControl - Cleaned\",\"FDM Resources/SpiralPatients - Cleaned\")\n",
        "#G_Spiral_Patient_Control, G_Spiral_Patient_Control_Back = train(\"FDM Resources/SpiralPatients - Cleaned\",\"FDM Resources/SpiralControl - Cleaned\")\n",
        "#G_Meander_Control_Patient, G_Meander_Control_Patient_Back = train(\"FDM Resources/MeanderControl\",\"FDM Resources/MeanderPatients\")\n",
        "#G_Meander_Patient_Control, G_Meander_Patient_Control_Back = train(\"FDM Resources/SpiralPatients\",\"FDM Resources/MeanderControl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using generators created in CycleGAN block to create images\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the same preprocessing transform used during training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"FDM Resources/SpiralControl\"\n",
        "output_folder = \"generated_patient\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Loop over all image files in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fake = G_Spiral_Control_Patient(input_tensor)\n",
        "\n",
        "        output_img = fake.squeeze(0).cpu()\n",
        "        output_img = (output_img * 0.5) + 0.5  # Denormalize\n",
        "\n",
        "        # Save output\n",
        "        output_pil = transforms.ToPILImage()(output_img)\n",
        "        output_file = os.path.join(output_folder, f\"generated_patient_{filename}\")\n",
        "        output_pil.save(output_file)\n",
        "\n",
        "        print(f\"Saved: {output_file}\")\n"
      ],
      "metadata": {
        "id": "Nd6cNv9LHcSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handcrafted Features\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set your folders here\n",
        "spiral_control_dir = '/content/drive/MyDrive/Financial Data Mining Project/FDM Resources/SpiralControl'\n",
        "# 'spiralcontrol'\n",
        "spiral_patients_dir = '/content/drive/MyDrive/Financial Data Mining Project/FDM Resources/SpiralPatients'\n",
        "#'spiralpd'\n",
        "\n",
        "sprial_gen_control = \"generated_control\"\n",
        "spiral_gen_patient = \"generated_patient\"\n",
        "meander_gen_control = \"generated_meander_control\"\n",
        "meander_gen_patient = \"generated_meander_patient\"\n",
        "\n",
        "# Functions\n",
        "def calculate_radial_deviation(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blur, 50, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        cnt = max(contours, key=cv2.contourArea)\n",
        "        M = cv2.moments(cnt)\n",
        "        if M['m00'] == 0:\n",
        "            return 0\n",
        "        cx = int(M['m10'] / M['m00'])\n",
        "        cy = int(M['m01'] / M['m00'])\n",
        "        deviations = [np.sqrt((pt[0][0] - cx)**2 + (pt[0][1] - cy)**2) for pt in cnt]\n",
        "        return np.std(deviations)\n",
        "    return 0\n",
        "\n",
        "def calculate_stroke_length(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    length = sum(cv2.arcLength(cnt, False) for cnt in contours)\n",
        "    return length\n",
        "\n",
        "def calculate_curvature(image):\n",
        "  def curvature(x, y): #calculating curvature as mag of r' - r'' / mag r' ^3\n",
        "    dx = np.gradient(x)\n",
        "    dy = np.gradient(y)\n",
        "    ddx = np.gradient(dx)\n",
        "    ddy = np.gradient(dy)\n",
        "    curv = (dx * ddy - dy * ddx) / ((dx**2 + dy**2)+1e-10)**(3/2) #+ 1e-10 because getting NaN for really small values\n",
        "    return curv\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.GaussianBlur(gray,(5,5),0)\n",
        "  _,thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2. THRESH_OTSU)\n",
        "  contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnt = max(contours, key=cv2.contourArea)\n",
        "  contour = cnt.squeeze() #extracts coords of contour points and remove uneccesary dimensions\n",
        "  x = contour[:, 0] #extracts x coords\n",
        "  y = contour[:, 1] #extract y coords\n",
        "  curvature = curvature(x,y) # calculate curvature\n",
        "  curv_variance = np.var(curvature) #find variance\n",
        "  return curv_variance\n",
        "\n",
        "def stroke_density(image):\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blur = cv2.GaussianBlur(gray,(5,5),0)\n",
        "  _,thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2. THRESH_OTSU)\n",
        "  #Stroke Density\n",
        "  #caluclate amount of white pixels in image after binary\n",
        "  white_pixels = np.sum(thresh == 255)\n",
        "  #calculate how many pixels\n",
        "  total_pixels = thresh.size\n",
        "  #density of the image can be viewed as how many white pixels are left after thresholding\n",
        "  stroke_density = white_pixels / total_pixels\n",
        "  return stroke_density\n",
        "\n",
        "# Analyze images\n",
        "results = []\n",
        "\n",
        "def process_directory(folder, label):\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "            path = os.path.join(folder, filename)\n",
        "            img = cv2.imread(path)\n",
        "            if img is not None:\n",
        "                rd = calculate_radial_deviation(img)\n",
        "                sl = calculate_stroke_length(img)\n",
        "                c = calculate_curvature(img)\n",
        "                sd = stroke_density(img)\n",
        "                results.append({\n",
        "                    'Filename': filename,\n",
        "                    'Group': label,\n",
        "                    'Radial Deviation': rd,\n",
        "                    'Stroke Length': sl,\n",
        "                    'Curvature': c,\n",
        "                    'Stroke Density': sd\n",
        "                })\n",
        "\n",
        "control_spiral = \"FDM Resources/Images - wCycleGAN/Control\"\n",
        "patient_spiral = \"FDM Resources/Images - wCycleGAN/Patient\"\n",
        "\n",
        "# Run analysis\n",
        "# process_directory(spiral_control_dir, 'Control')\n",
        "# process_directory(spiral_patients_dir, 'Patient')\n",
        "process_directory(control_spiral, 'Control')\n",
        "process_directory(patient_spiral, 'Patient')\n",
        "# process_directory(meander_gen_control, 'Control')\n",
        "# process_directory(meander_gen_patient, 'Patient')\n",
        "\n",
        "\n",
        "\n",
        "# Export or view results\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n",
        "\n",
        "# Save to Excel or CSV\n",
        "df.to_csv(\"spiral_gen_analysis_results.csv\", index=False)\n",
        "#boxplot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x='Group', y='Radial Deviation')\n",
        "plt.title(\"Radial Deviation by Group\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x='Group', y='Stroke Length')\n",
        "plt.title(\"Stroke Length by Group\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x='Group', y='Curvature')\n",
        "plt.title(\"Curvature by Group\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=df, x='Group', y='Stroke Density')\n",
        "plt.title(\"Stroke Density by Group\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#pca visualization\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "features = df[['Radial Deviation', 'Stroke Length', \"Curvature\", \"Stroke Density\"]]\n",
        "pca = PCA(n_components=4)\n",
        "pca_result = pca.fit_transform(features)\n",
        "\n",
        "df['PCA-RD'] = pca_result[:, 0] #rd\n",
        "df['PCA-SL'] = pca_result[:, 1] #sl\n",
        "df['PCA-C'] = pca_result[:, 2] #c\n",
        "df['PCA-SD'] = pca_result[:, 3] #sd\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=df, x='PCA-RD', y='PCA-SL', hue='Group', style='Group', s=100)\n",
        "plt.title('PCA Visualization of Handwriting Features (RD & SL)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=df, x='PCA-C', y='PCA-SL', hue='Group', style='Group', s=100)\n",
        "plt.title('PCA Visualization of Handwriting Features (C & SL)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=df, x='PCA-SD', y='PCA-C', hue='Group', style='Group', s=100)\n",
        "plt.title('PCA Visualization of Handwriting Features (SD & C)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "control_rd = df[df['Group'] == 'Control']['Radial Deviation']\n",
        "patient_rd = df[df['Group'] == 'Patient']['Radial Deviation']\n",
        "rd_tstat, rd_pval = ttest_ind(control_rd, patient_rd)\n",
        "\n",
        "control_sl = df[df['Group'] == 'Control']['Stroke Length']\n",
        "patient_sl = df[df['Group'] == 'Patient']['Stroke Length']\n",
        "sl_tstat, sl_pval = ttest_ind(control_sl, patient_sl)\n",
        "\n",
        "control_c = df[df['Group'] == 'Control']['Curvature']\n",
        "patient_c = df[df['Group'] == 'Patient']['Curvature']\n",
        "c_tstat, c_pval = ttest_ind(control_c, patient_c)\n",
        "\n",
        "control_sd = df[df['Group'] == 'Control']['Stroke Density']\n",
        "patient_sd = df[df['Group'] == 'Patient']['Stroke Density']\n",
        "sd_tstat, sd_pval = ttest_ind(control_sd, patient_sd)\n",
        "\n",
        "print(f\"Radial Deviation t-test p-value: {rd_pval:.4f}\")\n",
        "print(f\"Stroke Length t-test p-value: {sl_pval:.4f}\")\n",
        "print(f\"Curvature t-test p-value: {c_pval:.4f}\")\n",
        "print(f\"Stroke Density t-test p-value: {sd_pval:.4f}\")"
      ],
      "metadata": {
        "id": "fy3B53n3dPU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handcrafted features modeling\n",
        "#model building 3 diff models for comparison, Logistic Regression, Decision Tree, K-nearest-neigbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# X = handcrafted features, y = labels\n",
        "X = df[['Radial Deviation', 'Stroke Length', 'Curvature', 'Stroke Density']].values\n",
        "y = df['Group'].map({'Control': 0, 'Patient': 1}).values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "#confusion matrix for final comparison\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, display_labels=[\"Control\", \"Patient\"], cmap='Blues')\n",
        "plt.title(f\"Confusion Matrix - {name}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_RJWNWJ4YHdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vision Transformer (ViT)\n",
        "#Using Pre-Trained Model from Imagenet-21k, Transfer Learning\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "import numpy as np\n",
        "\n",
        "# Define whether to use GPU or CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "patch_size = 4\n",
        "\n",
        "root_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/Images - wCycleGAN'\n",
        "\n",
        "# Loading a pre-trained ViT model and feature extractor\n",
        "model_name = \"google/vit-base-patch16-224-in21k\"  # ViT model name from VIT paper\n",
        "model = ViTForImageClassification.from_pretrained(model_name, num_labels=len(os.listdir(root_dir)))\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model.to(device)\n",
        "\n",
        "# Transform to match ViT input size and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ViT expects 224x224 input images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained ViT normalization\n",
        "])\n",
        "\n",
        "#setting up the image folders for data loading\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir  # Path to the root directory containing categories\n",
        "        self.transform = transform\n",
        "        self.image_paths = []  # List to store paths of all images\n",
        "        self.labels = []  # List to store corresponding labels\n",
        "\n",
        "        # Get all the subdirectories (i.e., categories) in the root directory\n",
        "        self.class_names = os.listdir(root_dir)  # This gives you folder names (labels)\n",
        "\n",
        "        # Create a mapping from class name to class index (label)\n",
        "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.class_names)}\n",
        "\n",
        "        # Loop through each category folder\n",
        "        for class_name in self.class_names:\n",
        "            category_folder = os.path.join(root_dir, class_name)\n",
        "\n",
        "            # Ensure it's a folder (not a file)\n",
        "            if os.path.isdir(category_folder):\n",
        "                # Loop through each image in the folder\n",
        "                for img_name in os.listdir(category_folder):\n",
        "                    img_path = os.path.join(category_folder, img_name)\n",
        "\n",
        "                    # Only consider image files\n",
        "                    if img_path.endswith(('.jpg')):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.labels.append(self.class_to_idx[class_name])  # Assign label based on folder name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image and label based on the index\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        # Apply any transformations (like ToTensor, normalization, etc.)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomImageDataset(root_dir=root_dir, transform=transform)\n",
        "\n",
        "train_paths, test_paths = train_test_split(dataset.image_paths, test_size=0.2, random_state=15)\n",
        "train_paths, val_paths = train_test_split(train_paths, test_size=0.25, random_state=15)  # 0.25 * 0.8 = 0.2 validation\n",
        "\n",
        "# Function to copy files into the appropriate directories\n",
        "def copy_images_to_dir(image_paths, target_dir):\n",
        "    for path in image_paths:\n",
        "        class_name = path.split('\\\\')[-2]\n",
        "        target_class_dir = os.path.join(target_dir, class_name)\n",
        "        if not os.path.exists(target_class_dir):\n",
        "            os.makedirs(target_class_dir)\n",
        "            #print(f\"Created directory: {target_class_dir}\")\n",
        "        #print(f\"Copying image: {path} to {target_class_dir}\")\n",
        "        shutil.copy(path, target_class_dir)\n",
        "\n",
        "train_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/train'\n",
        "val_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/val'\n",
        "test_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/test'\n",
        "\n",
        "#FOR SEPARATION OF TRAINING,TEST,VALIDATION SETS INTO FILES\n",
        "\n",
        "copy_images_to_dir(train_paths, train_dir)\n",
        "copy_images_to_dir(val_paths, val_dir)\n",
        "copy_images_to_dir(test_paths, test_dir)\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#viewing labels\n",
        "# print(train_dataset.class_to_idx)\n",
        "\n",
        "# for images, labels in train_loader:\n",
        "#   print(images.shape)\n",
        "#   print(labels)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "# Model evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    true_labels = []\n",
        "    predicted_values = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            # Move images and labels to GPU if available\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            true_labels.extend(predicted.cpu().numpy())\n",
        "            predicted_values.extend(labels.cpu().numpy())\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy, true_labels, predicted_values\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 5  # Number of epochs with no improvement after which training will stop\n",
        "best_val_accuracy = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "training_loss_logger = []\n",
        "validation_acc_logger = []\n",
        "training_acc_logger = []\n",
        "\n",
        "valid_acc = 0\n",
        "train_acc = 0\n",
        "early_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Move images and labels to GPU if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs.logits, labels)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        training_loss_logger.append(loss.item())\n",
        "        optimizer.step()  # Optimizer step\n",
        "\n",
        "    # Evaluate after each epoch\n",
        "    val_accuracy, _, _ = evaluate_model(model, valid_loader)\n",
        "    training_accuracy,_,_ = evaluate_model(model, train_loader)\n",
        "\n",
        "    validation_acc_logger.append(val_accuracy)\n",
        "    training_acc_logger.append(training_accuracy)\n",
        "\n",
        "    # Early stopping based on validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        early_epoch = epoch\n",
        "        print(f\"Early stopping on epoch {epoch + 1}\")\n",
        "        break\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy * 100:.2f}%, Training Accuracy: {training_accuracy * 100:.2f}%\")\n",
        "\n",
        "#plotting training loss\n",
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, early_epoch, len(training_loss_logger))\n",
        "plt.plot(train_x, training_loss_logger)\n",
        "_ = plt.title(\"ViT Training Loss\")\n",
        "\n",
        "#plotting training and validation accuracy\n",
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, early_epoch, len(training_acc_logger))\n",
        "plt.plot(train_x, training_acc_logger, c = \"y\")\n",
        "valid_x = np.linspace(0, early_epoch, len(validation_acc_logger))\n",
        "plt.plot(valid_x, validation_acc_logger, c = \"k\")\n",
        "\n",
        "plt.title(\"ViT\")\n",
        "_ = plt.legend([\"Training accuracy\", \"Validation accuracy\"])\n",
        "\n",
        "# Test the model on the test set\n",
        "test_accuracy, test_labels, test_predicted = evaluate_model(model, test_loader)\n",
        "print(test_labels)\n",
        "print(test_predicted)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "#find model scores\n",
        "accuracy = accuracy_score(test_labels, test_predicted)\n",
        "print(f\"Test Accuracy: {accuracy}%\")\n",
        "precision = precision_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test Precision: {precision}%\")\n",
        "recall = recall_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test Recall: {recall}%\")\n",
        "f1 = f1_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test F1 Score: {f1}%\")\n",
        "\n",
        "#plot confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_predicted)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iMRTaRA222uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-Training Existing ViT Model with HandPD data\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "import numpy as np\n",
        "\n",
        "# Define whether to use GPU or CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-4\n",
        "patch_size = 4\n",
        "\n",
        "root_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/Images - wCycleGAN'\n",
        "\n",
        "# Loading a pre-trained ViT model and feature extractor\n",
        "model_name = \"google/vit-base-patch16-224-in21k\"  # ViT model name\n",
        "model = ViTForImageClassification.from_pretrained(model_name, num_labels=len(os.listdir(root_dir)))\n",
        "#, hidden_dropout_prob=0.5\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model.to(device)\n",
        "\n",
        "# Transform to match ViT input size and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ViT expects 224x224 input images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Pre-trained ViT normalization\n",
        "])\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir  # Path to the root directory containing categories\n",
        "        self.transform = transform\n",
        "        self.image_paths = []  # List to store paths of all images\n",
        "        self.labels = []  # List to store corresponding labels\n",
        "\n",
        "        # Get all the subdirectories (i.e., categories) in the root directory\n",
        "        self.class_names = os.listdir(root_dir)  # This gives you folder names (labels)\n",
        "\n",
        "        # Create a mapping from class name to class index (label)\n",
        "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.class_names)}\n",
        "\n",
        "        # Loop through each category folder\n",
        "        for class_name in self.class_names:\n",
        "            category_folder = os.path.join(root_dir, class_name)\n",
        "\n",
        "            # Ensure it's a folder (not a file)\n",
        "            if os.path.isdir(category_folder):\n",
        "                # Loop through each image in the folder\n",
        "                for img_name in os.listdir(category_folder):\n",
        "                    img_path = os.path.join(category_folder, img_name)\n",
        "\n",
        "                    # Only consider image files\n",
        "                    if img_path.endswith(('.jpg')):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.labels.append(self.class_to_idx[class_name])  # Assign label based on folder name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image and label based on the index\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        # Apply any transformations (like ToTensor, normalization, etc.)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "dataset = CustomImageDataset(root_dir=root_dir, transform=transform)\n",
        "\n",
        "train_paths, test_paths = train_test_split(dataset.image_paths, test_size=0.2, random_state=15)\n",
        "train_paths, val_paths = train_test_split(train_paths, test_size=0.25, random_state=15)  # 0.25 * 0.8 = 0.2 validation\n",
        "\n",
        "# Function to copy files into the appropriate directories\n",
        "def copy_images_to_dir(image_paths, target_dir):\n",
        "    for path in image_paths:\n",
        "        class_name = path.split('\\\\')[-2]\n",
        "        target_class_dir = os.path.join(target_dir, class_name)\n",
        "        if not os.path.exists(target_class_dir):\n",
        "            os.makedirs(target_class_dir)\n",
        "            #print(f\"Created directory: {target_class_dir}\")\n",
        "        #print(f\"Copying image: {path} to {target_class_dir}\")\n",
        "        shutil.copy(path, target_class_dir)\n",
        "\n",
        "train_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/train'\n",
        "val_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/val'\n",
        "test_dir = 'C:/Users/Thomas/coding/FDMProj/FDM Resources/test'\n",
        "\n",
        "#FOR SEPARATION OF TRAINING,TEST,VALIDATION SETS INTO FILES\n",
        "\n",
        "copy_images_to_dir(train_paths, train_dir)\n",
        "copy_images_to_dir(val_paths, val_dir)\n",
        "copy_images_to_dir(test_paths, test_dir)\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "#viewing labels\n",
        "# print(train_dataset.class_to_idx)\n",
        "\n",
        "# for images, labels in train_loader:\n",
        "#   print(images.shape)\n",
        "#   print(labels)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "num_epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "# Model evaluation function\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    true_labels = []\n",
        "    predicted_values = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            # Move images and labels to GPU if available\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            true_labels.extend(predicted.cpu().numpy())\n",
        "            predicted_values.extend(labels.cpu().numpy())\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy, true_labels, predicted_values\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 5  # Number of epochs with no improvement after which training will stop\n",
        "best_val_accuracy = 0.0\n",
        "epochs_without_improvement = 0\n",
        "\n",
        "training_loss_logger = []\n",
        "validation_acc_logger = []\n",
        "training_acc_logger = []\n",
        "\n",
        "valid_acc = 0\n",
        "train_acc = 0\n",
        "early_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set model to training mode\n",
        "    for images, labels in train_loader:\n",
        "        # Move images and labels to GPU if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs.logits, labels)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        training_loss_logger.append(loss.item())\n",
        "        optimizer.step()  # Optimizer step\n",
        "\n",
        "    # Evaluate after each epoch\n",
        "    val_accuracy, _, _ = evaluate_model(model, valid_loader)\n",
        "    training_accuracy,_,_ = evaluate_model(model, train_loader)\n",
        "\n",
        "    validation_acc_logger.append(val_accuracy)\n",
        "    training_acc_logger.append(training_accuracy)\n",
        "\n",
        "    # Early stopping based on validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        epochs_without_improvement = 0\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "\n",
        "    if epochs_without_improvement >= patience:\n",
        "        early_epoch = epoch\n",
        "        print(f\"Early stopping on epoch {epoch + 1}\")\n",
        "        break\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy * 100:.2f}%, Training Accuracy: {training_accuracy * 100:.2f}%\")\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, early_epoch, len(training_loss_logger))\n",
        "plt.plot(train_x, training_loss_logger)\n",
        "_ = plt.title(\"ViT Training Loss\")\n",
        "\n",
        "plt.figure(figsize = (10,5))\n",
        "train_x = np.linspace(0, early_epoch, len(training_acc_logger))\n",
        "plt.plot(train_x, training_acc_logger, c = \"y\")\n",
        "valid_x = np.linspace(0, early_epoch, len(validation_acc_logger))\n",
        "plt.plot(valid_x, validation_acc_logger, c = \"k\")\n",
        "\n",
        "plt.title(\"ViT\")\n",
        "_ = plt.legend([\"Training accuracy\", \"Validation accuracy\"])\n",
        "\n",
        "# Test the model on the test set\n",
        "test_accuracy, test_labels, test_predicted = evaluate_model(model, test_loader)\n",
        "print(test_labels)\n",
        "print(test_predicted)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predicted)\n",
        "print(f\"Test Accuracy: {accuracy}%\")\n",
        "precision = precision_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test Precision: {precision}%\")\n",
        "recall = recall_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test Recall: {recall}%\")\n",
        "f1 = f1_score(test_labels, test_predicted, average='weighted')\n",
        "print(f\"Test F1 Score: {f1}%\")\n",
        "\n",
        "cm = confusion_matrix(test_labels, test_predicted)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TiC_MJfAl-6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}